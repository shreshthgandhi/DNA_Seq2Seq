{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import DNA_reader as reader\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class SmallConfig(object):\n",
    "    \"\"\"Small Configuration\"\"\"\n",
    "    learning_rate = 1.0\n",
    "    max_grad_norm = 5\n",
    "    num_layers = 2\n",
    "    num_steps_encoder = 10\n",
    "    num_steps_decoder = 15\n",
    "    batch_size = 10\n",
    "    hidden_size = 200\n",
    "    max_epochs = 2\n",
    "    max_max_epochs = 4\n",
    "    lr_decay = 0.5\n",
    "    init_scale = 0.1\n",
    "    vocab_size = 8 # 3 extra tokens PAD,GO and EOS and 0 is unused\n",
    "    compression_dims = 2\n",
    "\n",
    "def get_config(flag='small'):\n",
    "    if flag=='small':\n",
    "        return SmallConfig()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Input and Model classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def data_type():\n",
    "    return tf.float32\n",
    "\n",
    "class DNA_input(object):\n",
    "    def __init__(self, config, data, name=None):\n",
    "        self.batch_size = batch_size = config.batch_size\n",
    "        self.num_steps_encoder = num_steps_encoder = config.num_steps_encoder\n",
    "        self.num_steps_decoder = num_steps_decoder = config.num_steps_decoder\n",
    "        self.epoch_size = len(data[0])//batch_size\n",
    "        (self.encoder_input, self.decoder_input,\n",
    "        self.decoder_targets, self.labels) = reader.DNA_producer(data, config, name)\n",
    "\n",
    "class DNA_seq_model(object):\n",
    "    def __init__(self, is_training, config, input_):\n",
    "        self._input = input_\n",
    "        batch_size = input_.batch_size\n",
    "        num_steps_encoder = input_.num_steps_encoder\n",
    "        num_steps_decoder = input_.num_steps_decoder\n",
    "        num_layers = config.num_layers\n",
    "        size = config.hidden_size\n",
    "        vocab_size = config.vocab_size\n",
    "        \n",
    "        lstm_cell = tf.nn.rnn_cell.BasicLSTMCell(size, forget_bias=0.0, state_is_tuple=True)\n",
    "        cell = tf.nn.rnn_cell.MultiRNNCell([lstm_cell] * num_layers, state_is_tuple=True)\n",
    "        self._initial_state = cell.zero_state(batch_size, data_type())\n",
    "        \n",
    "        softmax_w = tf.get_variable(\"softmax_w\", [size, vocab_size], dtype=data_type())\n",
    "        softmax_b = tf.get_variable(\"softmax_b\", [vocab_size], dtype=data_type())\n",
    "\n",
    "        with tf.device(\"/cpu:0\"):\n",
    "            embedding = tf.get_variable(\n",
    "                    \"embedding\", [vocab_size, size], dtype=data_type())\n",
    "            encoder_inputs = tf.nn.embedding_lookup(embedding, input_.encoder_input)\n",
    "            decoder_inputs = tf.nn.embedding_lookup(embedding, input_.decoder_input)\n",
    "        \n",
    "        def loop(prev, _):\n",
    "            prev = tf.matmul(prev, softmax_w) + softmax_b\n",
    "            prev_symbol = tf.stop_gradient(tf.argmax(prev, 1))\n",
    "            return tf.nn.embedding_lookup(embedding, prev_symbol)\n",
    " \n",
    "        compression_dims = config.compression_dims\n",
    "        encoder_outputs =[]\n",
    "        state = self._initial_state\n",
    "        with tf.variable_scope(\"RNN_encoder\"):\n",
    "            for time_step in range(num_steps_encoder):\n",
    "                if time_step > 0: tf.get_variable_scope().reuse_variables()\n",
    "                (cell_output, state) = cell(encoder_inputs[:, time_step, :], state)\n",
    "                encoder_outputs.append(cell_output)\n",
    "#         with tf.variable_scope(\"state_transform\"):\n",
    "        W_compress = tf.get_variable(\"W_compress\", [2*num_layers*size, compression_dims], dtype=data_type())\n",
    "        b_compress = tf.get_variable(\"bcompress\", [compression_dims], dtype=data_type())\n",
    "        W_expand = tf.get_variable(\"W_expand\", [compression_dims,2*num_layers*size], dtype=data_type())\n",
    "        b_expand = tf.get_variable(\"b_expand\", [2*num_layers*size], dtype=data_type())\n",
    "        \n",
    "        self._encoded_state = state\n",
    "        self.compressed_state = tf.reshape(tf.transpose(tf.pack(state),[0,1,3,2]),[-1,batch_size])\n",
    "        self.compressed_state = tf.transpose(self.compressed_state,[1,0])\n",
    "        \n",
    "        self._hidden_state = hidden_state = tf.matmul(self.compressed_state, W_compress) + b_compress\n",
    "        expanded_state = tf.matmul(hidden_state, W_expand) + b_expand\n",
    "        expanded_state = tf.reshape(tf.transpose(expanded_state,[1,0]),[num_layers,2,size,-1])\n",
    "        expanded_state = tf.transpose(expanded_state,[0,1,3,2])\n",
    "        expanded_state = tf.unpack(expanded_state, axis=0)\n",
    "        state_list = []\n",
    "        for i,layer in enumerate(expanded_state):\n",
    "            state_list.append(tuple(tf.unpack(layer, axis=0)))\n",
    "        \n",
    "        self.recovered_state = tuple(state_list)\n",
    "\n",
    "        expanded_state= self.recovered_state\n",
    "        \n",
    "        decoder_inputs_list = tf.unpack(decoder_inputs, axis=1)\n",
    "        (decoder_outputs, state) = tf.nn.seq2seq.rnn_decoder(decoder_inputs_list, expanded_state, cell, \n",
    "                                                             loop_function=loop if not(is_training) else None)\n",
    "        decoder_output = tf.reshape(tf.concat(1, decoder_outputs), [-1, size])\n",
    "\n",
    "        logits = tf.matmul(decoder_output, softmax_w) + softmax_b\n",
    "        self._probabilities = tf.reshape(tf.nn.softmax(logits), [batch_size, num_steps_decoder, vocab_size])\n",
    "        \n",
    "        loss = tf.nn.seq2seq.sequence_loss_by_example(\n",
    "                [logits],\n",
    "                [tf.reshape(input_.decoder_targets, [-1])],\n",
    "                [tf.ones([batch_size * num_steps_decoder], dtype=data_type())])\n",
    "        self._cost = cost = tf.reduce_sum(loss) / batch_size\n",
    "        self._decoded_state = state\n",
    "        \n",
    "        if not is_training:\n",
    "            return\n",
    "\n",
    "        self._lr = tf.Variable(0.0, trainable=False)\n",
    "        tvars = tf.trainable_variables()\n",
    "        grads, _ = tf.clip_by_global_norm(tf.gradients(cost, tvars),config.max_grad_norm)\n",
    "        optimizer = tf.train.GradientDescentOptimizer(self._lr)\n",
    "        self._train_op = optimizer.apply_gradients(\n",
    "                zip(grads, tvars),\n",
    "                global_step=tf.contrib.framework.get_or_create_global_step())\n",
    "\n",
    "        self._new_lr = tf.placeholder(\n",
    "                tf.float32, shape=[], name=\"new_learning_rate\")\n",
    "        self._lr_update = tf.assign(self._lr, self._new_lr)\n",
    "\n",
    "    def assign_lr(self, session, lr_value):\n",
    "        session.run(self._lr_update, feed_dict={self._new_lr: lr_value})\n",
    "\n",
    "    @property\n",
    "    def input(self):\n",
    "        return self._input\n",
    "\n",
    "    @property\n",
    "    def initial_state(self):\n",
    "        return self._initial_state\n",
    "    @property\n",
    "    def encoded_state(self):\n",
    "        return self._encoded_state\n",
    "\n",
    "    @property\n",
    "    def cost(self):\n",
    "        return self._cost\n",
    "\n",
    "    @property\n",
    "    def decoded_state(self):\n",
    "        return self._decoded_state\n",
    "    @property\n",
    "    def hidden_state(self):\n",
    "        return self._hidden_state\n",
    "\n",
    "    @property\n",
    "    def lr(self):\n",
    "        return self._lr\n",
    "\n",
    "    @property\n",
    "    def train_op(self):\n",
    "        return self._train_op\n",
    "    @property\n",
    "    def probabilities(self):\n",
    "        return self._probabilties\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def run_epoch(session, model, eval_op=None, verbose=False):\n",
    "    \"\"\"Run the model for a single epoch\"\"\"\n",
    "    start_time=time.time()\n",
    "    costs = 0.0\n",
    "    iters = 0\n",
    "    state = session.run(model.initial_state)\n",
    "    \n",
    "    fetches = {\n",
    "        \"cost\": model.cost,\n",
    "        \"encoded_state\": model.encoded_state,\n",
    "    }\n",
    "    if eval_op is not None:\n",
    "        fetches[\"eval_op\"] = eval_op\n",
    "    for step in range(model.input.epoch_size):\n",
    "        feed_dict={}\n",
    "        for i, (c,h) in enumerate(model.initial_state):\n",
    "            feed_dict[c] = state[i].c\n",
    "            feed_dict[h] = state[i].h\n",
    "        vals = session.run(fetches, feed_dict)\n",
    "        cost = vals[\"cost\"]\n",
    "#         state = vals[\"encoded_state\"]\n",
    "        costs += cost\n",
    "        iters += model.input.num_steps_decoder\n",
    "        \n",
    "        if verbose and step % (model.input.epoch_size //10) ==10:\n",
    "            print(\"%.3f perplexity: %.3f speed %.0f nps\" %\n",
    "                 (step * 1.0/model.input.epoch_size, np.exp(costs / iters),\n",
    "                 iters * model.input.batch_size /(time.time()-start_time)))\n",
    "    return np.exp(costs / iters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def visualize_states(session, model, config):\n",
    "    state = session.run(model.initial_state)\n",
    "    fetches = {\n",
    "        \"hidden_state\" : model.hidden_state,\n",
    "        \"labels\" : model.input.labels,\n",
    "    }\n",
    "    batch_size = model.input.batch_size\n",
    "    epoch_size = model.input.epoch_size\n",
    "    hidden_state = np.zeros([model.input.epoch_size*model.input.batch_size, config.compression_dims])\n",
    "    labels = np.zeros([model.input.epoch_size*model.input.batch_size])\n",
    "    for step in range(model.input.epoch_size):\n",
    "        feed_dict={}\n",
    "        for i, (c,h) in enumerate(model.initial_state):\n",
    "            feed_dict[c] = state[i].c\n",
    "            feed_dict[h] = state[i].h\n",
    "        vals = session.run(fetches, feed_dict)\n",
    "        hidden_state[step*batch_size:(step+1)*batch_size] = vals[\"hidden_state\"]\n",
    "        labels[step*batch_size:(step+1)*batch_size] = vals[\"labels\"]\n",
    "    x_hidden = hidden_state[:,0]\n",
    "    x_max = np.max(abs(x_hidden))\n",
    "    x_hidden = (x_hidden / x_max) * 100\n",
    "    y_hidden = hidden_state[:,1]\n",
    "    y_max = np.max(abs(y_hidden))\n",
    "    y_hidden = (y_hidden / y_max) * 100\n",
    "    plt.figure(0)\n",
    "    plt.scatter(x_hidden, y_hidden, s=10, c=labels)\n",
    "    plt.title('Hidden States of system')\n",
    "    return x_hidden, y_hidden, labels\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Data generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_size = 10000\n",
    "seq_length = 10\n",
    "raw_data=reader.DNA_read(data_size,seq_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python2.7/dist-packages/numpy/core/numeric.py:301: FutureWarning: in the future, full([10000, 10], 7) will return an array of dtype('int64')\n",
      "  format(shape, fill_value, array(fill_value).dtype), FutureWarning)\n",
      "/usr/lib/python2.7/dist-packages/numpy/core/numeric.py:301: FutureWarning: in the future, full([10000, 15], 7) will return an array of dtype('int64')\n",
      "  format(shape, fill_value, array(fill_value).dtype), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Learning rate: 1.000\n",
      "0.010 perplexity: 10.480 speed 1351 nps\n",
      "0.110 perplexity: 2.571 speed 3011 nps\n",
      "0.210 perplexity: 1.811 speed 3634 nps\n",
      "0.310 perplexity: 1.591 speed 3976 nps\n",
      "0.410 perplexity: 1.469 speed 4128 nps\n",
      "0.510 perplexity: 1.390 speed 4271 nps\n",
      "0.610 perplexity: 1.338 speed 4381 nps\n",
      "0.710 perplexity: 1.326 speed 4467 nps\n",
      "0.810 perplexity: 1.306 speed 4534 nps\n",
      "0.910 perplexity: 1.288 speed 4559 nps\n",
      "Epoch: 1 Train Perplexity: 1.271\n",
      "Epoch: 2 Learning rate: 1.000\n",
      "0.010 perplexity: 1.186 speed 5415 nps\n",
      "0.110 perplexity: 1.112 speed 5078 nps\n",
      "0.210 perplexity: 1.127 speed 4991 nps\n",
      "0.310 perplexity: 1.110 speed 4992 nps\n",
      "0.410 perplexity: 1.132 speed 4948 nps\n",
      "0.510 perplexity: 1.157 speed 4911 nps\n",
      "0.610 perplexity: 1.168 speed 4914 nps\n",
      "0.710 perplexity: 1.205 speed 4906 nps\n",
      "0.810 perplexity: 1.214 speed 4943 nps\n",
      "0.910 perplexity: 1.213 speed 4935 nps\n",
      "Epoch: 2 Train Perplexity: 1.206\n",
      "Epoch: 3 Learning rate: 0.500\n",
      "0.010 perplexity: 1.075 speed 5412 nps\n",
      "0.110 perplexity: 1.076 speed 5055 nps\n",
      "0.210 perplexity: 1.096 speed 5056 nps\n",
      "0.310 perplexity: 1.095 speed 4973 nps\n",
      "0.410 perplexity: 1.094 speed 5012 nps\n",
      "0.510 perplexity: 1.101 speed 5070 nps\n",
      "0.610 perplexity: 1.107 speed 5124 nps\n",
      "0.710 perplexity: 1.122 speed 5161 nps\n",
      "0.810 perplexity: 1.131 speed 5184 nps\n",
      "0.910 perplexity: 1.135 speed 5206 nps\n",
      "Epoch: 3 Train Perplexity: 1.136\n",
      "Epoch: 4 Learning rate: 0.250\n",
      "0.010 perplexity: 1.076 speed 5413 nps\n",
      "0.110 perplexity: 1.051 speed 5419 nps\n",
      "0.210 perplexity: 1.057 speed 5418 nps\n",
      "0.310 perplexity: 1.054 speed 5247 nps\n",
      "0.410 perplexity: 1.058 speed 5107 nps\n",
      "0.510 perplexity: 1.052 speed 5152 nps\n",
      "0.610 perplexity: 1.045 speed 5161 nps\n",
      "0.710 perplexity: 1.040 speed 5187 nps\n",
      "0.810 perplexity: 1.036 speed 5181 nps\n",
      "0.910 perplexity: 1.033 speed 5156 nps\n",
      "Epoch: 4 Train Perplexity: 1.031\n",
      "[  5.30753702 -23.06059006  12.98693629 ...,   5.30753702  -1.07322165\n",
      "  13.82625257]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAh0AAAFyCAYAAABRKmj1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSaqFoUOSJNXi/wPJqSutCC2oOAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f47f57dcf10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "config = get_config()\n",
    "with tf.Graph().as_default():\n",
    "    initializer = tf.random_uniform_initializer(-config.init_scale,\n",
    "                                               config.init_scale)\n",
    "    with tf.name_scope(\"Train\"):\n",
    "        train_input = DNA_input(config, raw_data, \"TrainInput\")\n",
    "        with tf.variable_scope(\"Model\", reuse=None, initializer=initializer):\n",
    "            m = DNA_seq_model(is_training=True, config=config, input_=train_input)\n",
    "    sv = tf.train.Supervisor(logdir='test2')\n",
    "    with sv.managed_session() as session:\n",
    "        for i in range(config.max_max_epochs):\n",
    "            lr_decay = config.lr_decay ** max(i+1-config.max_epochs, 0.0)\n",
    "            m.assign_lr(session, config.learning_rate * lr_decay)\n",
    "#             print(session.run(m.recovered_state[0]).shape)\n",
    "            print(\"Epoch: %d Learning rate: %.3f\" % (i + 1, session.run(m.lr)))\n",
    "            train_perplexity = run_epoch(session, m, eval_op=m.train_op,\n",
    "                                         verbose=True)\n",
    "            print(\"Epoch: %d Train Perplexity: %.3f\" % (i + 1, train_perplexity))\n",
    "        x,y,l = visualize_states(session, m, config)\n",
    "        \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-2fd7a4bf3f15>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0msv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSupervisor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogdir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'test2'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0msv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmanaged_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;31m#     b = x2.eval(session=session)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#     c = x3.eval(session=session)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'x1' is not defined"
     ]
    }
   ],
   "source": [
    "sv = tf.train.Supervisor(logdir='test2')\n",
    "with sv.managed_session() as session:\n",
    "    a,b,c,d = session.run([x1,x2,x3,x4])\n",
    "#     b = x2.eval(session=session)\n",
    "#     c = x3.eval(session=session)\n",
    "    print(a)\n",
    "    print(b)\n",
    "    print(c)\n",
    "    print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a=(1,2)\n",
    "b=(a[0]*1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
